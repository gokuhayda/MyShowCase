{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9tcen7XN3G2"
      },
      "source": [
        "# ğŸ“ Tree Embedding Protocols â€” Camera-Ready (Crash-Resilient)\n",
        "\n",
        "**Paper:** *Dimensional Efficiency Bounds for Embedding Hierarchical Metric Structures*\n",
        "\n",
        "## Execution Plan\n",
        "\n",
        "| Step | Protocol | Mode | Time (T4) |\n",
        "|------|----------|------|----------|\n",
        "| 1 | E1 | exact | ~10 min |\n",
        "| 2 | E1 | stochastic | ~25 min |\n",
        "| 3 | E2 | stochastic | ~30 min |\n",
        "| 4 | E3 | stochastic | ~15 min |\n",
        "| **Total** | | | **~80 min** |\n",
        "\n",
        "âš¡ **Crash-Resilient:** All outputs saved to Google Drive. Auto-resume on reconnect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t-IgBSuN3G4",
        "outputId": "a18c416f-84dc-47ca-e393-d42ab89b5cb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "âœ… Google Drive mounted\n",
            "ğŸ“ BASE_DIR: /content/drive/MyDrive/cgt_tree_runs/\n",
            "ğŸ“ Checkpoints: /content/drive/MyDrive/cgt_tree_runs//checkpoints\n",
            "ğŸ“ Results: /content/drive/MyDrive/cgt_tree_runs//results\n",
            "ğŸ“ Logs: /content/drive/MyDrive/cgt_tree_runs//logs\n"
          ]
        }
      ],
      "source": [
        "# @title 0ï¸âƒ£ Mount Google Drive + Setup Persistence\n",
        "from google.colab import drive\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Base directory for all outputs\n",
        "BASE_DIR = \"/content/drive/MyDrive/cgt_tree_runs/\"\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(BASE_DIR, exist_ok=True)\n",
        "os.makedirs(f\"{BASE_DIR}/checkpoints\", exist_ok=True)\n",
        "os.makedirs(f\"{BASE_DIR}/results\", exist_ok=True)\n",
        "os.makedirs(f\"{BASE_DIR}/logs\", exist_ok=True)\n",
        "\n",
        "print(f\"âœ… Google Drive mounted\")\n",
        "print(f\"ğŸ“ BASE_DIR: {BASE_DIR}\")\n",
        "print(f\"ğŸ“ Checkpoints: {BASE_DIR}/checkpoints\")\n",
        "print(f\"ğŸ“ Results: {BASE_DIR}/results\")\n",
        "print(f\"ğŸ“ Logs: {BASE_DIR}/logs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FebNFFWFN3G5",
        "outputId": "44dd6b92-f322-4533-ff8d-152de9da9cb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Š Current progress: 0 steps completed\n"
          ]
        }
      ],
      "source": [
        "# @title 0ï¸âƒ£.1 Progress Tracking Functions\n",
        "\n",
        "PROGRESS_FILE = f\"{BASE_DIR}/progress.txt\"\n",
        "\n",
        "def save_progress(marker: str):\n",
        "    \"\"\"Save completed step marker to Drive.\"\"\"\n",
        "    completed = load_progress()\n",
        "    if marker not in completed:\n",
        "        completed.append(marker)\n",
        "    with open(PROGRESS_FILE, \"w\") as f:\n",
        "        f.write(\"\\n\".join(completed))\n",
        "    print(f\"ğŸ’¾ Progress saved: {marker}\")\n",
        "\n",
        "def load_progress() -> list:\n",
        "    \"\"\"Load list of completed steps.\"\"\"\n",
        "    if os.path.exists(PROGRESS_FILE):\n",
        "        with open(PROGRESS_FILE, \"r\") as f:\n",
        "            return [line.strip() for line in f.readlines() if line.strip()]\n",
        "    return []\n",
        "\n",
        "def is_completed(marker: str) -> bool:\n",
        "    \"\"\"Check if step was already completed.\"\"\"\n",
        "    return marker in load_progress()\n",
        "\n",
        "def reset_progress():\n",
        "    \"\"\"Reset all progress (use with caution).\"\"\"\n",
        "    if os.path.exists(PROGRESS_FILE):\n",
        "        os.remove(PROGRESS_FILE)\n",
        "    print(\"âš ï¸ Progress reset\")\n",
        "\n",
        "def save_result(name: str, data: dict):\n",
        "    \"\"\"Save result to Drive.\"\"\"\n",
        "    filepath = f\"{BASE_DIR}/results/{name}.json\"\n",
        "    with open(filepath, \"w\") as f:\n",
        "        json.dump(data, f, indent=2)\n",
        "    print(f\"ğŸ’¾ Result saved: {filepath}\")\n",
        "\n",
        "def load_result(name: str) -> dict:\n",
        "    \"\"\"Load result from Drive.\"\"\"\n",
        "    filepath = f\"{BASE_DIR}/results/{name}.json\"\n",
        "    if os.path.exists(filepath):\n",
        "        with open(filepath, \"r\") as f:\n",
        "            return json.load(f)\n",
        "    return None\n",
        "\n",
        "def log_message(msg: str):\n",
        "    \"\"\"Append message to log file.\"\"\"\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    logfile = f\"{BASE_DIR}/logs/run_log.txt\"\n",
        "    with open(logfile, \"a\") as f:\n",
        "        f.write(f\"[{timestamp}] {msg}\\n\")\n",
        "\n",
        "# Show current progress\n",
        "completed = load_progress()\n",
        "print(f\"\\nğŸ“Š Current progress: {len(completed)} steps completed\")\n",
        "for step in completed:\n",
        "    print(f\"   âœ… {step}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrHOCvOCN3G6",
        "outputId": "497f2a4b-05f1-4ecd-a10d-1123b4231c83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m842.1/842.1 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.6/48.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for hopcroftkarp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "âœ… Dependencies installed\n"
          ]
        }
      ],
      "source": [
        "# @title 1ï¸âƒ£ Install Dependencies\n",
        "!pip install -q torch numpy scipy ripser\n",
        "print(\"âœ… Dependencies installed\")\n",
        "log_message(\"Dependencies installed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "KCFnQxIGN3G6",
        "outputId": "0404491a-5cad-44e7-9213-756cdd288982"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload tree_protocols_standalone.py:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-39a1c47d-f542-4326-80a4-e41a438b3eec\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-39a1c47d-f542-4326-80a4-e41a438b3eec\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving tree_protocols_standalone.py to tree_protocols_standalone.py\n",
            "ğŸ’¾ Module backed up to Drive: /content/drive/MyDrive/cgt_tree_runs//tree_protocols_standalone.py\n"
          ]
        }
      ],
      "source": [
        "# @title 2ï¸âƒ£ Upload Module\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# Check if module already exists in Drive\n",
        "module_path_drive = f\"{BASE_DIR}/tree_protocols_standalone.py\"\n",
        "module_path_local = \"/content/tree_protocols_standalone.py\"\n",
        "\n",
        "if os.path.exists(module_path_drive):\n",
        "    # Copy from Drive to local\n",
        "    shutil.copy(module_path_drive, module_path_local)\n",
        "    print(f\"âœ… Module loaded from Drive: {module_path_drive}\")\n",
        "else:\n",
        "    # Upload and save to Drive\n",
        "    print(\"Upload tree_protocols_standalone.py:\")\n",
        "    uploaded = files.upload()\n",
        "    # Save copy to Drive for future runs\n",
        "    if os.path.exists(module_path_local):\n",
        "        shutil.copy(module_path_local, module_path_drive)\n",
        "        print(f\"ğŸ’¾ Module backed up to Drive: {module_path_drive}\")\n",
        "\n",
        "log_message(\"Module loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vckmrfvYN3G6",
        "outputId": "c29a8602-a94f-453f-ee47-8ca91a4b65c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ENVIRONMENT CHECK\n",
            "============================================================\n",
            "âœ… Module imported\n",
            "ğŸ–¥ï¸  Device: cuda\n",
            "ğŸ“Š EXACT threshold: N â‰¤ 10,000\n",
            "ğŸ“Š STOCHASTIC: K = min(100Ã—N, 2,000,000)\n",
            "ğŸ® GPU: Tesla T4\n",
            "ğŸ’¾ VRAM: 15.8 GB\n",
            "ğŸ“ Output dir: /content/drive/MyDrive/cgt_tree_runs/\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# @title 3ï¸âƒ£ Import + Verify Environment\n",
        "import sys\n",
        "sys.path.insert(0, '/content')\n",
        "\n",
        "from tree_protocols_standalone import (\n",
        "    run_protocol_e1,\n",
        "    run_protocol_e2,\n",
        "    run_protocol_e3,\n",
        "    get_device,\n",
        "    clear_gpu,\n",
        "    EXACT_THRESHOLD,\n",
        "    K_MAX,\n",
        "    K_MULTIPLIER\n",
        ")\n",
        "\n",
        "import torch\n",
        "device = get_device()\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ENVIRONMENT CHECK\")\n",
        "print(\"=\"*60)\n",
        "print(f\"âœ… Module imported\")\n",
        "print(f\"ğŸ–¥ï¸  Device: {device}\")\n",
        "print(f\"ğŸ“Š EXACT threshold: N â‰¤ {EXACT_THRESHOLD:,}\")\n",
        "print(f\"ğŸ“Š STOCHASTIC: K = min({K_MULTIPLIER}Ã—N, {K_MAX:,})\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"ğŸ® GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"ğŸ’¾ VRAM: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"âš ï¸  WARNING: No GPU detected. Runtime will be slow.\")\n",
        "print(f\"ğŸ“ Output dir: {BASE_DIR}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "log_message(f\"Environment ready. Device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnfLl7Q6N3G6"
      },
      "source": [
        "---\n",
        "## ğŸ”¬ Protocol E1: Distortion vs Dimension\n",
        "\n",
        "**Objective:** Measure embedding dimension required for <10% distortion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Q1DjHdpN3G7",
        "outputId": "d7c16b06-ef3b-47c4-9bb1-eda63947df9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Protocol E1: Distortion vs Dimension\n",
            "  Tree: T_{3,7} with 3,280 nodes\n",
            "  Mode: EXACT\n",
            "  Dimensions: [4, 8, 16, 32]\n",
            "  Trials: 3, Epochs: 500\n",
            "  Device: cuda\n",
            "\n",
            "  Dimension 4:\n",
            "    Euclidean:  0.2983 Â± 0.0000\n",
            "    Hyperbolic: 0.8415 Â± 0.0003\n",
            "\n",
            "  Dimension 8:\n",
            "    Euclidean:  0.2131 Â± 0.0001\n",
            "    Hyperbolic: 0.7588 Â± 0.0002\n",
            "\n",
            "  Dimension 16:\n",
            "    Euclidean:  0.1760 Â± 0.0000\n",
            "    Hyperbolic: 0.6383 Â± 0.0003\n",
            "\n",
            "  Dimension 32:\n",
            "    Euclidean:  0.1571 Â± 0.0001\n",
            "    Hyperbolic: 0.4964 Â± 0.0002\n",
            "ğŸ’¾ Result saved: /content/drive/MyDrive/cgt_tree_runs//results/E1_exact.json\n",
            "ğŸ’¾ Progress saved: E1_exact\n",
            "\n",
            "============================================================\n",
            "âœ… E1 EXACT COMPLETE\n",
            "============================================================\n",
            "  RESULT_E1_DIM_EUCLIDEAN: >32\n",
            "  RESULT_E1_DIM_HYPERBOLIC: >32\n",
            "  RESULT_E1_RATIO: N/A\n",
            "  RESULT_E1_STATUS: NOT CONFIRMED\n"
          ]
        }
      ],
      "source": [
        "# @title 4ï¸âƒ£ E1 â€” EXACT Mode (Validation)\n",
        "# Purpose: Sanity check, confirm code works\n",
        "# Tree: T_{3,7} = 3,280 nodes\n",
        "# Time: ~10 min\n",
        "\n",
        "STEP_NAME = \"E1_exact\"\n",
        "\n",
        "if is_completed(STEP_NAME):\n",
        "    print(f\"â­ï¸ Skipping {STEP_NAME} (already completed)\")\n",
        "    results_e1_exact = load_result(STEP_NAME)\n",
        "else:\n",
        "    log_message(f\"Starting {STEP_NAME}\")\n",
        "\n",
        "    results_e1_exact = run_protocol_e1(\n",
        "        b=3,\n",
        "        d=7,\n",
        "        dimensions=[4, 8, 16, 32],\n",
        "        n_trials=3,\n",
        "        n_epochs=500,\n",
        "        seed=42,\n",
        "        mode=\"exact\",\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    # Save to Drive\n",
        "    save_result(STEP_NAME, results_e1_exact)\n",
        "    save_progress(STEP_NAME)\n",
        "    log_message(f\"Completed {STEP_NAME}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ… E1 EXACT COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "for k, v in results_e1_exact.get(\"latex\", {}).items():\n",
        "    print(f\"  {k}: {v}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2bSq5AVN3G7",
        "outputId": "3a7a9c02-ac29-47cb-d5c8-355d91ca44a3"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Protocol E1: Distortion vs Dimension\n",
            "  Tree: T_{3,12} with 797,161 nodes\n",
            "  Mode: STOCHASTIC\n",
            "  Dimensions: [4, 8, 16, 32, 64]\n",
            "  Trials: 5, Epochs: 300\n",
            "  Device: cuda\n",
            "\n",
            "  Dimension 4:\n"
          ]
        }
      ],
      "source": [
        "# @title 5ï¸âƒ£ E1 â€” STOCHASTIC Mode (Production)\n",
        "# Purpose: Main result for paper\n",
        "# Tree: T_{3,12} = 265,720 nodes\n",
        "# Time: ~25 min\n",
        "\n",
        "STEP_NAME = \"E1_stochastic\"\n",
        "\n",
        "if is_completed(STEP_NAME):\n",
        "    print(f\"â­ï¸ Skipping {STEP_NAME} (already completed)\")\n",
        "    results_e1_stochastic = load_result(STEP_NAME)\n",
        "else:\n",
        "    log_message(f\"Starting {STEP_NAME}\")\n",
        "\n",
        "    results_e1_stochastic = run_protocol_e1(\n",
        "        b=3,\n",
        "        d=12,\n",
        "        dimensions=[4, 8, 16, 32, 64],\n",
        "        n_trials=5,\n",
        "        n_epochs=300,\n",
        "        seed=42,\n",
        "        mode=\"stochastic\",\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    # Save to Drive\n",
        "    save_result(STEP_NAME, results_e1_stochastic)\n",
        "    save_progress(STEP_NAME)\n",
        "    log_message(f\"Completed {STEP_NAME}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ… E1 STOCHASTIC COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "for k, v in results_e1_stochastic.get(\"latex\", {}).items():\n",
        "    print(f\"  {k}: {v}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnuQX89bN3G7"
      },
      "source": [
        "---\n",
        "## ğŸ”¬ Protocol E2: Depth Scaling\n",
        "\n",
        "**Objective:** Fit power-law D(d) = AÂ·d^Î± to distortion curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "q9b_opv2N3G7"
      },
      "outputs": [],
      "source": [
        "# @title 6ï¸âƒ£ E2 â€” STOCHASTIC Mode\n",
        "# Purpose: Scaling analysis\n",
        "# Depths: 5â†’13 (crosses exact/stochastic boundary)\n",
        "# Time: ~30 min\n",
        "\n",
        "STEP_NAME = \"E2_stochastic\"\n",
        "\n",
        "if is_completed(STEP_NAME):\n",
        "    print(f\"â­ï¸ Skipping {STEP_NAME} (already completed)\")\n",
        "    results_e2 = load_result(STEP_NAME)\n",
        "else:\n",
        "    log_message(f\"Starting {STEP_NAME}\")\n",
        "\n",
        "    results_e2 = run_protocol_e2(\n",
        "        b=3,\n",
        "        dim=32,\n",
        "        depths=[5, 7, 9, 11, 13],\n",
        "        n_trials=5,\n",
        "        n_epochs=300,\n",
        "        seed=42,\n",
        "        mode=\"stochastic\",\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    # Save to Drive\n",
        "    save_result(STEP_NAME, results_e2)\n",
        "    save_progress(STEP_NAME)\n",
        "    log_message(f\"Completed {STEP_NAME}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ… E2 COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "for k, v in results_e2.get(\"latex\", {}).items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "print(f\"\\nPower-law exponents:\")\n",
        "print(f\"  Î±_Euclidean  = {results_e2['fit']['alpha_euclidean']:.3f}\")\n",
        "print(f\"  Î±_Hyperbolic = {results_e2['fit']['alpha_hyperbolic']:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgtNXGMEN3G7"
      },
      "source": [
        "---\n",
        "## ğŸ”¬ Protocol E3: Topological Integrity\n",
        "\n",
        "**Objective:** Detect spurious 1-cycles (Î²â‚) via persistent homology"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pUmkG0DUN3G7"
      },
      "outputs": [],
      "source": [
        "# @title 7ï¸âƒ£ E3 â€” STOCHASTIC Mode\n",
        "# Purpose: Topological verification\n",
        "# Depths: 5,7,9 (limited by ripser complexity)\n",
        "# Time: ~15 min\n",
        "\n",
        "STEP_NAME = \"E3_stochastic\"\n",
        "\n",
        "if is_completed(STEP_NAME):\n",
        "    print(f\"â­ï¸ Skipping {STEP_NAME} (already completed)\")\n",
        "    results_e3 = load_result(STEP_NAME)\n",
        "else:\n",
        "    log_message(f\"Starting {STEP_NAME}\")\n",
        "\n",
        "    results_e3 = run_protocol_e3(\n",
        "        b=3,\n",
        "        depths=[5, 7, 9],\n",
        "        dim=32,\n",
        "        n_trials=3,\n",
        "        n_epochs=300,\n",
        "        persistence_threshold=0.1,\n",
        "        seed=42,\n",
        "        mode=\"stochastic\",\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    # Save to Drive\n",
        "    save_result(STEP_NAME, results_e3)\n",
        "    save_progress(STEP_NAME)\n",
        "    log_message(f\"Completed {STEP_NAME}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ… E3 COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "for k, v in results_e3.get(\"latex\", {}).items():\n",
        "    print(f\"  {k}: {v}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60-IvosnN3G8"
      },
      "source": [
        "---\n",
        "## ğŸ“Š Results Export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-YvuqsON3G8"
      },
      "outputs": [],
      "source": [
        "# @title 8ï¸âƒ£ Generate LaTeX Commands\n",
        "print(\"=\"*70)\n",
        "print(\"ğŸ“ LaTeX Commands â€” Copy to paper preamble\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "all_latex = {}\n",
        "all_latex.update(results_e1_exact.get(\"latex\", {}))\n",
        "all_latex.update(results_e1_stochastic.get(\"latex\", {}))\n",
        "all_latex.update(results_e2.get(\"latex\", {}))\n",
        "all_latex.update(results_e3.get(\"latex\", {}))\n",
        "\n",
        "# Save LaTeX to file\n",
        "latex_file = f\"{BASE_DIR}/results/latex_commands.tex\"\n",
        "with open(latex_file, \"w\") as f:\n",
        "    f.write(\"% === Auto-generated LaTeX commands ===\\n\")\n",
        "    f.write(f\"% Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
        "\n",
        "    f.write(\"% === E1 Results ===\\n\")\n",
        "    for k, v in sorted(all_latex.items()):\n",
        "        if \"E1\" in k:\n",
        "            cmd = k.replace(\"_\", \"\")\n",
        "            f.write(f\"\\\\newcommand{{\\\\{cmd}}}{{{v}}}\\n\")\n",
        "            print(f\"\\\\newcommand{{\\\\{cmd}}}{{{v}}}\")\n",
        "\n",
        "    f.write(\"\\n% === E2 Results ===\\n\")\n",
        "    print(\"\\n% === E2 Results ===\")\n",
        "    for k, v in sorted(all_latex.items()):\n",
        "        if \"E2\" in k:\n",
        "            cmd = k.replace(\"_\", \"\")\n",
        "            f.write(f\"\\\\newcommand{{\\\\{cmd}}}{{{v}}}\\n\")\n",
        "            print(f\"\\\\newcommand{{\\\\{cmd}}}{{{v}}}\")\n",
        "\n",
        "    f.write(\"\\n% === E3 Results ===\\n\")\n",
        "    print(\"\\n% === E3 Results ===\")\n",
        "    for k, v in sorted(all_latex.items()):\n",
        "        if \"E3\" in k or \"B1\" in k:\n",
        "            cmd = k.replace(\"_\", \"\")\n",
        "            f.write(f\"\\\\newcommand{{\\\\{cmd}}}{{{v}}}\\n\")\n",
        "            print(f\"\\\\newcommand{{\\\\{cmd}}}{{{v}}}\")\n",
        "\n",
        "print(f\"\\nğŸ’¾ LaTeX saved to: {latex_file}\")\n",
        "log_message(\"LaTeX commands generated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKjF_9-kN3G8"
      },
      "outputs": [],
      "source": [
        "# @title 9ï¸âƒ£ Summary Report\n",
        "print(\"=\"*70)\n",
        "print(\"ğŸ“Š EXECUTION SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "completed_steps = load_progress()\n",
        "print(f\"\\nâœ… Completed steps: {len(completed_steps)}/4\")\n",
        "for step in completed_steps:\n",
        "    print(f\"   â€¢ {step}\")\n",
        "\n",
        "print(f\"\\nğŸ“ All outputs saved to: {BASE_DIR}\")\n",
        "print(f\"\\nğŸ“„ Files in results/:\")\n",
        "for f in os.listdir(f\"{BASE_DIR}/results\"):\n",
        "    size = os.path.getsize(f\"{BASE_DIR}/results/{f}\")\n",
        "    print(f\"   â€¢ {f} ({size:,} bytes)\")\n",
        "\n",
        "log_message(\"Execution summary generated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnZQpmg3N3G8"
      },
      "outputs": [],
      "source": [
        "# @title ğŸ§¹ Final Cleanup\n",
        "clear_gpu()\n",
        "print(\"âœ… GPU memory released\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ‰ ALL PROTOCOLS COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nğŸ“ Results available at: {BASE_DIR}\")\n",
        "log_message(\"All protocols complete. GPU released.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWBpPgP1N3G8"
      },
      "outputs": [],
      "source": [
        "# @title ğŸ“¦ (Optional) Zip Results for Download\n",
        "import shutil\n",
        "\n",
        "zip_name = f\"{BASE_DIR}/results_tree_run\"\n",
        "shutil.make_archive(zip_name, 'zip', f\"{BASE_DIR}/results\")\n",
        "\n",
        "print(f\"âœ… Results zipped: {zip_name}.zip\")\n",
        "print(f\"\\nTo download, run:\")\n",
        "print(f\"  from google.colab import files\")\n",
        "print(f\"  files.download('{zip_name}.zip')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxBTyv25N3G8"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ“„ Methods Note (for paper)\n",
        "\n",
        "```\n",
        "For trees with more than 10â´ nodes, explicit construction of full\n",
        "pairwise distance matrices becomes infeasible due to quadratic memory\n",
        "requirements. To ensure scalability, we replace the deterministic stress\n",
        "objective with an unbiased Monte Carlo estimator via random subsampling\n",
        "of K = min(2Ã—10â¶, 100N) node pairs per epoch. Tree distances are computed\n",
        "on-the-fly via LCA traversal, avoiding materialization of the distance matrix.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## âš ï¸ DO NOT RUN\n",
        "\n",
        "- `mode=\"exact\"` for `d > 8`\n",
        "- `depths` containing values > 13 in E3\n",
        "- `n_epochs > 500`\n",
        "- `dims` containing 128 or 256\n",
        "\n",
        "---\n",
        "\n",
        "**Author:** Ã‰ric Gustavo Reis de Sena  \n",
        "**License:** CC BY-NC-SA 4.0"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}