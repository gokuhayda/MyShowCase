# ğŸ“Š A/B Testing Kata â€” Sample Size Calculator

> â€œConduct experiments and develop hypotheses using advanced statistics.â€

Este exercÃ­cio demonstra raciocÃ­nio estatÃ­stico rigoroso, engenharia de software limpa e a capacidade de traduzir conceitos matemÃ¡ticos complexos para decisÃµes prÃ¡ticas â€” competÃªncias essenciais para Cientistas de Dados SÃªniores e Engenheiros de ML em empresas de alto nÃ­vel.

---

## ğŸ¬ O Problema

A maior parte dos cientistas de dados iniciantes comete o mesmo erro crÃ­tico:

- Roda um teste A/B sem planejamento.  
- VÃª um aumento de 5% na mÃ©trica alvo.  
- Conclui prematuramente que a "variante B ganhou".  
- Sobe para produÃ§Ã£o.

O que foi ignorado?

- âŒ Tamanho mÃ­nimo de amostra.  
- âŒ Poder estatÃ­stico (Power).  
- âŒ SignificÃ¢ncia estatÃ­stica (Alpha).  
- âŒ Viabilidade temporal.  

Isso frequentemente resulta em decisÃµes baseadas em **falsos positivos** â€” ruÃ­do aleatÃ³rio interpretado como sinal.

---

## ğŸ¯ Objetivo do ExercÃ­cio

Este kata implementa uma classe em Python para calcular quantos usuÃ¡rios sÃ£o necessÃ¡rios **por grupo** antes de iniciar um experimento A/B.

Esse cÃ¡lculo Ã© essencial para evitar:

- Testes inconclusivos  
- Peeking (olhar antes da hora)  
- P-hacking  ((ou data dredging, fishing) Ã© um erro estatÃ­stico grave que acontece quando alguÃ©m manipula o processo de anÃ¡lise atÃ© â€œencontrarâ€
um resultado estatisticamente significativo â€” mesmo quando esse resultado nÃ£o Ã© real.Ã‰ basicamente â€œforÃ§arâ€ os dados a contar uma histÃ³ria que eles nÃ£o contam.)
- DecisÃµes enviesadas baseadas em intuiÃ§Ã£o  

### A Linguagem dos Stakeholders

Stakeholders nÃ£o querem saber de p-values.  
Eles querem respostas como:

> â€œEm quantos dias teremos um resultado confiÃ¡vel?â€

Este kata demonstra como transformar **estatÃ­stica em engenharia**, e **engenharia em decisÃµes de negÃ³cio**.

---

## ğŸ§± TraduÃ§Ã£o TÃ©cnica: Do MatemÃ¡tico para o NegÃ³cio

A estatÃ­stica aqui nÃ£o Ã© tratada como nÃºmeros abstratos, mas como ferramentas de **gestÃ£o de risco**.

### **Alpha (Î±) â€” â€œA Trava de SeguranÃ§aâ€**

- **TÃ©cnico:** Probabilidade de erro tipo I.  
- **Executivo:** Evita que recursos sejam investidos em uma feature que â€œparece boaâ€ mas nÃ£o Ã©.

### **Power (1âˆ’Î²) â€” â€œO Detector de Oportunidadesâ€**

- **TÃ©cnico:** Probabilidade de rejeitar H0 quando H1 Ã© verdadeira.  
- **Executivo:** Garante que boas ideias nÃ£o sejam descartadas como â€œnÃ£o conclusivasâ€.

### **MDE â€” Minimum Detectable Effect (â€œA RÃ©gua de RelevÃ¢nciaâ€)**

- **TÃ©cnico:** Menor diferenÃ§a detectÃ¡vel pelo teste.  
- **Executivo:** Evita gastar meses testando para descobrir melhorias irrelevantes.

### **Tamanho da Amostra â€” â€œO Custo do Experimentoâ€**

- **TÃ©cnico:** NÃºmero calculado via Z-Test Power Analysis.  
- **Executivo:** Antes de comeÃ§ar, respondemos:  
  > â€œVale a pena travar esse trÃ¡fego por 2 semanas para testar essa hipÃ³tese?â€

---

## ğŸ“ Estrutura do Projeto
applied-statistics-katas/
â””â”€â”€ ab-testing/
â”œâ”€â”€ README.md # VocÃª estÃ¡ aqui
â””â”€â”€ ab_testing.py # ImplementaÃ§Ã£o da classe SampleSizeCalculator


---

## ğŸ” Sobre a ImplementaÃ§Ã£o

A classe utilitÃ¡ria encapsula o cÃ¡lculo estatÃ­stico para determinar o tamanho da amostra necessÃ¡ria para testes A/B de **proporÃ§Ãµes** (ex: taxa de conversÃ£o).

### ParÃ¢metros padrÃ£o da indÃºstria

| ParÃ¢metro | Valor | Significado |
|----------|-------|-------------|
| Alpha (Î±) | 5% | Aceitamos 5% de chance de falso positivo |
| Power | 80% | Chance de detectar efeito real |

Esses valores refletem o padrÃ£o adotado em empresas de engenharia e produto com rigor cientÃ­fico.

---

## ğŸ“ Pergunta Frequente de Entrevista (Behavioral/Technical)

### O CenÃ¡rio

O Product Manager diz:

> â€œVamos rodar o teste sÃ³ por dois dias. Se a Variante B estiver ganhando, a gente para e sobe pra produÃ§Ã£o!â€

Seu cÃ¡lculo apontava que eram necessÃ¡rios **14 dias de dados**.

### A Pergunta

**Que erro estatÃ­stico isso representa e por que Ã© perigoso?**

### Resposta SÃªnior

Isso se chama **Peeking** (Early Stopping sem correÃ§Ã£o).

- **O Erro:** Nos primeiros dias, a variÃ¢ncia Ã© alta, o comportamento dos dados segue um random walk.  
- **O Risco:** Aumenta drasticamente a chance de falso positivo.  
- **A ConsequÃªncia:** VocÃª pode estar implantando algo que **nÃ£o funciona** â€” ou pior, prejudica mÃ©tricas reais.

---

## ğŸ› ï¸ Como Executar
from ab_testing import SampleSizeCalculator

calculator = SampleSizeCalculator()

tamanho_amostra = calculator.calculate_sample_size(
baseline_rate=0.10,
minimum_detectable_effect=0.02
)

print(f"NecessÃ¡rios {tamanho_amostra} usuÃ¡rios por variante.")

---
