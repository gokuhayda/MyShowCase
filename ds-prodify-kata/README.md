# ğŸ­ Production ML Pipeline

Pipeline de Machine Learning de nÃ­vel sÃªnior aplicando princÃ­pios SOLID, injeÃ§Ã£o de dependÃªncias e arquitetura modular.

---

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#-visÃ£o-geral)
- [Arquitetura](#-arquitetura)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Conceitos Aplicados](#-conceitos-aplicados)
- [Como Usar](#-como-usar)
- [Componentes](#-componentes)
- [Testes](#-testes)
- [Extensibilidade](#-extensibilidade)

---

## ğŸ¯ VisÃ£o Geral

Este projeto demonstra como refatorar um notebook jupyteriano em uma pipeline de produÃ§Ã£o testÃ¡vel e expansÃ­vel. A arquitetura separa responsabilidades em componentes independentes que podem ser testados isoladamente.

### Problema Original

```python
# âŒ CÃ³digo Spaghetti (Notebook)
df = pd.read_csv("vendas.csv")
df = df.dropna()
df['total'] = df['qtd'] * df['preco']
model = LinearRegression()
model.fit(df[['qtd', 'preco']], df['total'])
```

### SoluÃ§Ã£o SÃªnior

```python
# âœ… CÃ³digo Modular (ProduÃ§Ã£o)
pipeline = TrainingPipeline(
    loader=CsvLoader(),
    cleaner=SalesDataCleaner(),
    trainer=ModelTrainer()
)
model = pipeline.run("vendas.csv")
```

---

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         TrainingPipeline (Orchestrator)      â”‚
â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Loader â”‚â†’ â”‚ Cleaner â”‚â†’ â”‚ ModelTrainer â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“             â†“              â†“
   LoaderStrategy CleanerStrategy  Trainer
   (Protocol)     (Protocol)       (Class)
```

### PrincÃ­pios Aplicados

- **Single Responsibility Principle (SRP)**: Cada classe tem uma Ãºnica razÃ£o para mudar
- **Dependency Injection**: Componentes sÃ£o injetados no construtor
- **Protocol-based Design**: Contratos sem heranÃ§a
- **Open/Closed Principle**: ExtensÃ­vel sem modificaÃ§Ã£o

---

## ğŸ“ Estrutura do Projeto

```
ds-prodify-kata
/kata/
    â”œâ”€â”€ loaders.py          # Interface e implementaÃ§Ã£o de carregamento
    â”œâ”€â”€ cleaners.py         # Interface e implementaÃ§Ã£o de limpeza
    â”œâ”€â”€ trainers.py         # LÃ³gica de treinamento
    â”œâ”€â”€ orchestrator.py     # OrquestraÃ§Ã£o da pipeline
â””â”€â”€ tests/
    â”œâ”€â”€ test_loaders.py
    â”œâ”€â”€ test_cleaners.py
    â”œâ”€â”€ test_trainers.py
    â””â”€â”€ test_pipeline.py
```

---

## ğŸ’¡ Conceitos Aplicados

### 1. Protocols (Duck Typing ExplÃ­cito)

```python
# Interface - define o CONTRATO
class LoaderStrategy(Protocol):
    def load(self, path: str) -> pd.DataFrame: ...

# ImplementaÃ§Ã£o - cumpre o CONTRATO
class CsvLoader:
    def load(self, path: str) -> pd.DataFrame:
        return pd.read_csv(path)
```

**Por que isso importa?**

- Sem heranÃ§a obrigatÃ³ria
- Type hints funcionam corretamente
- Facilita mocking em testes
- Permite mÃºltiplas implementaÃ§Ãµes

### 2. Dependency Injection

```python
@dataclass
class TrainingPipeline:
    loader: LoaderStrategy      # â† Injetado
    cleaner: CleanerStrategy    # â† Injetado
    trainer: ModelTrainer       # â† Injetado
```

**BenefÃ­cios:**

- Pipeline nÃ£o conhece implementaÃ§Ãµes concretas
- FÃ¡cil trocar componentes
- Testabilidade mÃ¡xima

### 3. Single Responsibility Principle

Cada classe tem **uma Ãºnica responsabilidade**:

| Classe | Responsabilidade |
|--------|------------------|
| `CsvLoader` | Carregar dados de CSV |
| `SalesDataCleaner` | Limpar e transformar dados |
| `ModelTrainer` | Treinar modelo |
| `TrainingPipeline` | Orquestrar o fluxo |

---

## ğŸš€ Como Usar

### Uso BÃ¡sico

```python
from orchestrator import TrainingPipeline
from loaders import CsvLoader
from cleaners import SalesDataCleaner
from trainers import ModelTrainer

# Monta a pipeline
pipeline = TrainingPipeline(
    loader=CsvLoader(),
    cleaner=SalesDataCleaner(),
    trainer=ModelTrainer()
)

# Executa
model = pipeline.run("vendas.csv")
```

### SaÃ­da Esperada

```
ğŸš€ Iniciando Pipeline de ProduÃ§Ã£o...
ğŸ“‚ Lendo CSV: vendas.csv
ğŸ§¹ Limpando dados...
ğŸ¤– Treinando modelo com 3 linhas...
âœ… Pipeline finalizada com sucesso!
```

---

## ğŸ”§ Componentes

### 1. LoaderStrategy (loaders.py)

**Interface:**
```python
class LoaderStrategy(Protocol):
    def load(self, path: str) -> pd.DataFrame: ...
```

**ImplementaÃ§Ã£o:**
```python
class CsvLoader:
    def load(self, path: str) -> pd.DataFrame:
        print(f"ğŸ“‚ Lendo CSV: {path}")
        return pd.DataFrame({
            'qtd': [1, 2, None, 4], 
            'preco': [10.0, 20.0, 30.0, 40.0]
        })
```

**Responsabilidade:** Carregar dados da fonte

### 2. CleanerStrategy (cleaners.py)

**Interface:**
```python
class CleanerStrategy(Protocol):
    def clean(self, df: pd.DataFrame) -> pd.DataFrame: ...
```

**ImplementaÃ§Ã£o:**
```python
class SalesDataCleaner:
    def clean(self, df: pd.DataFrame) -> pd.DataFrame:
        print("ğŸ§¹ Limpando dados...")
        df = df.dropna().copy()
        df['total'] = df['qtd'] * df['preco']
        return df
```

**Responsabilidade:** Limpar e transformar dados

### 3. ModelTrainer (trainers.py)

```python
class ModelTrainer:
    def train(self, df: pd.DataFrame) -> Any:
        X = df[['qtd', 'preco']]
        y = df['total']
        
        model = LinearRegression()
        model.fit(X, y)
        return model
```

**Responsabilidade:** Treinar modelo com dados limpos

### 4. TrainingPipeline (orchestrator.py)

```python
@dataclass
class TrainingPipeline:
    loader: LoaderStrategy
    cleaner: CleanerStrategy
    trainer: ModelTrainer
    
    def run(self, input_path: str) -> Any:
        raw_data = self.loader.load(input_path)
        clean_data = self.cleaner.clean(raw_data)
        model = self.trainer.train(clean_data)
        return model
```

**Responsabilidade:** Orquestrar o fluxo de execuÃ§Ã£o

---

## ğŸ§ª Testes

### Por que essa arquitetura facilita testes?

Cada componente pode ser testado **isoladamente**, sem dependÃªncias externas.

### Exemplo: Testando SalesDataCleaner

```python
import pandas as pd
from cleaners import SalesDataCleaner

def test_cleaner_removes_nulls_and_creates_total():
    # Arrange
    df = pd.DataFrame({
        "qtd": [1, None, 3],
        "preco": [10, 20, 30]
    })
    cleaner = SalesDataCleaner()
    
    # Act
    result = cleaner.clean(df)
    
    # Assert
    assert len(result) == 2  # Linha com None foi removida
    assert list(result["total"]) == [10, 90]  # 1*10, 3*30
```

### Exemplo: Testando com Mock

```python
from unittest.mock import Mock
from orchestrator import TrainingPipeline

def test_pipeline_calls_components_in_order():
    # Arrange
    mock_loader = Mock()
    mock_loader.load.return_value = pd.DataFrame({"qtd": [1], "preco": [10]})
    
    mock_cleaner = Mock()
    mock_cleaner.clean.return_value = pd.DataFrame({"qtd": [1], "preco": [10], "total": [10]})
    
    mock_trainer = Mock()
    mock_trainer.train.return_value = "trained_model"
    
    pipeline = TrainingPipeline(
        loader=mock_loader,
        cleaner=mock_cleaner,
        trainer=mock_trainer
    )
    
    # Act
    result = pipeline.run("fake_path.csv")
    
    # Assert
    mock_loader.load.assert_called_once_with("fake_path.csv")
    mock_cleaner.clean.assert_called_once()
    mock_trainer.train.assert_called_once()
    assert result == "trained_model"
```

### Cobertura de Testes

| Componente | Tipo de Teste | O que Testar |
|------------|---------------|--------------|
| `CsvLoader` | UnitÃ¡rio | Carregamento correto |
| `SalesDataCleaner` | UnitÃ¡rio | RemoÃ§Ã£o de nulls, cÃ¡lculo de total |
| `ModelTrainer` | UnitÃ¡rio | PreparaÃ§Ã£o de X e y, chamada do fit |
| `TrainingPipeline` | IntegraÃ§Ã£o | Fluxo completo com mocks |

---

## ğŸ”„ Extensibilidade

### Adicionando Nova Fonte de Dados

```python
class BigQueryLoader:
    def load(self, path: str) -> pd.DataFrame:
        # path seria uma query SQL
        from google.cloud import bigquery
        client = bigquery.Client()
        return client.query(path).to_dataframe()

# Usar na pipeline SEM MUDAR NADA
pipeline = TrainingPipeline(
    loader=BigQueryLoader(),  # â† Nova implementaÃ§Ã£o
    cleaner=SalesDataCleaner(),
    trainer=ModelTrainer()
)
```

### Adicionando Nova EstratÃ©gia de Limpeza

```python
class AdvancedDataCleaner:
    def clean(self, df: pd.DataFrame) -> pd.DataFrame:
        # LÃ³gica mais sofisticada
        df = df.dropna()
        df = self.remove_outliers(df)
        df = self.feature_engineering(df)
        df['total'] = df['qtd'] * df['preco']
        return df
    
    def remove_outliers(self, df): ...
    def feature_engineering(self, df): ...

# Usar na pipeline SEM MUDAR NADA
pipeline = TrainingPipeline(
    loader=CsvLoader(),
    cleaner=AdvancedDataCleaner(),  # â† Nova implementaÃ§Ã£o
    trainer=ModelTrainer()
)
```

### Adicionando Novo Modelo

```python
class XGBoostTrainer:
    def train(self, df: pd.DataFrame) -> Any:
        import xgboost as xgb
        X = df[['qtd', 'preco']]
        y = df['total']
        
        model = xgb.XGBRegressor()
        model.fit(X, y)
        return model

# Usar na pipeline SEM MUDAR NADA
pipeline = TrainingPipeline(
    loader=CsvLoader(),
    cleaner=SalesDataCleaner(),
    trainer=XGBoostTrainer()  # â† Nova implementaÃ§Ã£o
)
```

---

## ğŸ“ CenÃ¡rio de Entrevista

### Pergunta: "O modelo estÃ¡ treinando com dados sujos. Onde vocÃª investiga?"

**OpÃ§Ãµes:**
- A) `TrainingPipeline`
- B) `ModelTrainer`
- C) `SalesDataCleaner`

**Resposta Correta: C**

**Justificativa:**

1. **Pipeline (A)** apenas orquestra - nÃ£o transforma dados
2. **Trainer (B)** apenas treina com o que recebe - nÃ£o valida
3. **Cleaner (C)** Ã© responsÃ¡vel pela qualidade dos dados

**Teste para verificar:**

```python
def test_cleaner_handles_edge_cases():
    df = pd.DataFrame({
        "qtd": [1, None, -5, 0],  # casos extremos
        "preco": [10, 20, 30, 0]
    })
    
    cleaner = SalesDataCleaner()
    result = cleaner.clean(df)
    
    # Verificar se dados sujos foram tratados
    assert result['qtd'].isnull().sum() == 0
    assert (result['qtd'] > 0).all()
```

---

## ğŸ“Š ComparaÃ§Ã£o: Antes vs Depois

| Aspecto | Notebook (Antes) | Pipeline (Depois) |
|---------|------------------|-------------------|
| **Testabilidade** | âŒ ImpossÃ­vel testar | âœ… 100% testÃ¡vel |
| **ManutenÃ§Ã£o** | âŒ CÃ³digo acoplado | âœ… Componentes isolados |
| **Extensibilidade** | âŒ Requer reescrever | âœ… Adicionar nova classe |
| **Reusabilidade** | âŒ Copiar/colar | âœ… Importar mÃ³dulo |
| **Debugging** | âŒ Global scope | âœ… Isolamento claro |
| **ColaboraÃ§Ã£o** | âŒ Um Ãºnico arquivo | âœ… MÃºltiplos mÃ³dulos |

---

## ğŸ† BenefÃ­cios da Arquitetura

### 1. Testabilidade Total
- Testes unitÃ¡rios sem arquivos reais
- Mocks simples e eficazes
- Isolamento de componentes

### 2. ManutenÃ§Ã£o Facilitada
- Bug em limpeza? â†’ Olhe `cleaners.py`
- Bug em carregamento? â†’ Olhe `loaders.py`
- MudanÃ§a de escopo? â†’ Substitua um componente

### 3. Onboarding RÃ¡pido
- Estrutura clara
- Responsabilidades Ã³bvias
- DocumentaÃ§Ã£o via tipo

### 4. ProduÃ§Ã£o-Ready
- Logging centralizado (pode adicionar)
- Error handling modular
- ConfiguraÃ§Ã£o externa (pode adicionar)
- CI/CD friendly

---

## ğŸš¦ PrÃ³ximos Passos

1. **Adicionar logging estruturado**
   ```python
   import logging
   logger = logging.getLogger(__name__)
   ```

2. **Adicionar configuraÃ§Ã£o externa**
   ```python
   from dataclasses import dataclass
   
   @dataclass
   class PipelineConfig:
       input_path: str
       model_type: str
       cleaning_strategy: str
   ```

3. **Adicionar validaÃ§Ã£o de dados**
   ```python
   from pydantic import BaseModel, validator
   
   class SalesData(BaseModel):
       qtd: int
       preco: float
       
       @validator('qtd')
       def qtd_must_be_positive(cls, v):
           if v <= 0:
               raise ValueError('qtd must be positive')
           return v
   ```

4. **Adicionar mÃ©tricas e monitoramento**
   ```python
   from dataclasses import dataclass
   from datetime import datetime
   
   @dataclass
   class PipelineMetrics:
       start_time: datetime
       end_time: datetime
       rows_processed: int
       rows_cleaned: int
       model_accuracy: float
   ```

---

## ğŸ“š ReferÃªncias

- [Python Protocols - PEP 544](https://peps.python.org/pep-0544/)
- [SOLID Principles](https://en.wikipedia.org/wiki/SOLID)
- [Dependency Injection Pattern](https://en.wikipedia.org/wiki/Dependency_injection)
- [Martin Fowler - Refactoring](https://refactoring.com/)

---

## ğŸ¤ Contribuindo

Este projeto Ã© um exemplo didÃ¡tico. ContribuiÃ§Ãµes sÃ£o bem-vindas:

1. Adicione novos Loaders (Parquet, BigQuery, S3)
2. Adicione novos Cleaners (outlier removal, feature engineering)
3. Adicione novos Trainers (XGBoost, LightGBM, Neural Networks)
4. Melhore a cobertura de testes

---

## ğŸ“ LicenÃ§a

Este projeto Ã© livre para uso educacional e demonstraÃ§Ã£o de conceitos.

---

## ğŸ‘¨â€ğŸ’» Autor

Desenvolvido como material de estudo para pair programming sÃªnior e entrevistas tÃ©cnicas.

**Conceitos-chave:** SOLID, Dependency Injection, Protocol-based Design, Test-Driven Development

---

## ğŸ¯ ConclusÃ£o

Esta arquitetura transforma cÃ³digo experimental em **cÃ³digo de produÃ§Ã£o**:

- âœ… TestÃ¡vel
- âœ… ManutenÃ­vel
- âœ… ExtensÃ­vel
- âœ… Documentado
- âœ… Type-safe

**Perfeito para demonstrar em pair programming em empresas como ThoughtWorks, onde design evolutivo e qualidade de cÃ³digo sÃ£o fundamentais.**
