# ğŸ—ï¸ Arquitetura do Sistema

## VisÃ£o Geral

Este projeto implementa o **Trainer Pattern** para desacoplar a lÃ³gica de treino de Deep Learning das responsabilidades auxiliares (logging, checkpointing, early stopping).

## DecisÃµes de Design

### 1. Por que Protocol ao invÃ©s de ABC?

**DecisÃ£o:** Usar `Protocol` (PEP 544) ao invÃ©s de `abc.ABC`.

**RazÃ£o:**
- âœ… Duck typing nativo do Python
- âœ… NÃ£o forÃ§a heranÃ§a (composiÃ§Ã£o > heranÃ§a)
- âœ… Mais flexÃ­vel para testes (mocks simples)
```python
# âŒ Com ABC (forÃ§a heranÃ§a)
class MyCallback(Callback):
    def on_epoch_end(self, ...): ...

# âœ… Com Protocol (duck typing)
class MyCallback:  # NÃ£o precisa herdar!
    def on_epoch_end(self, ...): ...
```

### 2. Por que retornar bool em on_epoch_end?

**DecisÃ£o:** `on_epoch_end` retorna `bool` indicando se deve parar.

**RazÃ£o:**
- âœ… Simples e explÃ­cito
- âœ… Evita efeitos colaterais ocultos (callbacks nÃ£o modificam Trainer)
- âœ… Segue convenÃ§Ã£o de Keras/PyTorch Lightning

**Alternativas consideradas:**
- âŒ Callback modificar `trainer.stop_training` diretamente (tight coupling)
- âŒ LanÃ§ar exceÃ§Ã£o `StopTraining` (exceptions for control flow)

### 3. Por que nÃ£o usar heranÃ§a para Trainer?

**DecisÃ£o:** Trainer Ã© uma classe concreta, nÃ£o abstrata.

**RazÃ£o:**
- âœ… ComposiÃ§Ã£o via callbacks Ã© mais flexÃ­vel
- âœ… Evita "explosion" de subclasses (TrainerWithEarlyStopping, TrainerWithCheckpoint...)
- âœ… Open/Closed Principle: estender via callbacks, nÃ£o heranÃ§a

## Fluxo de ExecuÃ§Ã£o
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  trainer.fit(dataloader, epochs=10) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  _notify_callbacks("on_train_begin")â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  Loop Ã‰pocas  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  _train_one_epoch() â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ _notify_callbacks(         â”‚
   â”‚   "on_epoch_end",          â”‚
   â”‚   epoch, logs              â”‚
   â”‚ )                          â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Verificar se â”‚
         â”‚ deve parar   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Testabilidade

### PrincÃ­pio: Isolar Responsabilidades

Cada callback pode ser testado **sem rodar rede neural**:
```python
# Testar early stopping sem GPU, sem dados, sem modelo!
def test_early_stopping():
    callback = EarlyStopping(patience=2)
    
    # Simular Ã©pocas ruins
    callback.on_epoch_end(0, {"loss": 1.0})
    should_stop = callback.on_epoch_end(1, {"loss": 1.0})
    
    assert should_stop is True
```

### BenefÃ­cios:
- âš¡ Testes rÃ¡pidos (milissegundos vs. minutos)
- ğŸ”¬ Isolamento perfeito (bug em checkpoint nÃ£o afeta early stopping)
- ğŸ“Š Coverage alto (testar todos edge cases Ã© viÃ¡vel)

## Extensibilidade

### Adicionar novo callback: 3 passos

1. **Criar classe com mÃ©todos do Protocol:**
```python
class WandbLogger:
    def on_train_begin(self, logs):
        wandb.init(project="my-project")
    
    def on_epoch_end(self, epoch, logs):
        wandb.log(logs)
        return False
```

2. **NÃ£o modificar Trainer** (Open/Closed Principle)

3. **Usar via composiÃ§Ã£o:**
```python
trainer = Trainer(callbacks=[WandbLogger()])
```

## ComparaÃ§Ã£o com Frameworks Reais

| Aspecto | Este Projeto | Keras | PyTorch Lightning |
|---------|-------------|-------|-------------------|
| Interface | Protocol | ABC | ABC |
| Hooks | 2 (begin, epoch_end) | 7+ | 20+ |
| Complexidade | Educacional | ProduÃ§Ã£o | ProduÃ§Ã£o |
| PropÃ³sito | Demonstrar padrÃ£o | Framework completo | Framework completo |

## Trade-offs

### âœ… Vantagens desta abordagem:
- Simples de entender
- FÃ¡cil de testar
- ExtensÃ­vel sem modificaÃ§Ã£o

### âš ï¸ LimitaÃ§Ãµes (por ser educacional):
- NÃ£o cobre batch-level hooks
- NÃ£o suporta multi-GPU
- NÃ£o tem logger integrado (W&B, MLflow)

Para produÃ§Ã£o, use PyTorch Lightning ou Keras diretamente.

## ReferÃªncias

- [Keras Callbacks Guide](https://keras.io/guides/writing_your_own_callbacks/)
- [PyTorch Lightning Callbacks](https://lightning.ai/docs/pytorch/stable/extensions/callbacks.html)
- [Design Patterns: Elements of Reusable OO Software](https://en.wikipedia.org/wiki/Design_Patterns) (Gang of Four)
