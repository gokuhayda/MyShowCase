# ğŸ”¥ Deep Learning Trainer Refactoring Kata

[![Tests](https://github.com/seu-usuario/dl-refactor-kata/actions/workflows/tests.yml/badge.svg)](https://github.com/seu-usuario/dl-refactor-kata/actions)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

DemonstraÃ§Ã£o de **Software Engineering aplicado a Deep Learning**: como transformar cÃ³digo espaguete de treinamento em sistema extensÃ­vel e testÃ¡vel usando **Callback Pattern**.

---

## ğŸ¯ Objetivo

Este projeto demonstra a aplicaÃ§Ã£o de princÃ­pios SOLID e Design Patterns em cÃ³digo de Machine Learning, especificamente:

- âœ… **Strategy Pattern** via Callbacks
- âœ… **Open/Closed Principle** (extensÃ­vel sem modificar core)
- âœ… **Dependency Inversion** (abstraÃ§Ãµes antes de implementaÃ§Ãµes)
- âœ… **Testabilidade** (callbacks isolados do loop de treino)

---

## ğŸ“– O Problema

### âŒ CÃ³digo Espaguete (Antes)
```python
# TÃ­pico cÃ³digo de Kaggle/Research
for epoch in range(100):
    for batch in dataloader:
        optimizer.zero_grad()
        loss = model(batch)
        loss.backward()
        optimizer.step()

    # Mistura I/O, logging e lÃ³gica de parada
    if epoch % 10 == 0:
        print(f"Epoch {epoch} loss={loss}")
        torch.save(model, "ckpt.pth")
    if loss < 0.01:
        break  # Early stopping hardcoded
```

**Problemas:**
- ğŸš« NÃ£o testÃ¡vel (precisa rodar rede inteira)
- ğŸš« NÃ£o extensÃ­vel (adicionar Slack notification = mexer no loop)
- ğŸš« Responsabilidades misturadas (matemÃ¡tica + I/O + controle)

---

### âœ… SoluÃ§Ã£o com Trainer Pattern (Depois)
```python
trainer = Trainer(
    model=MyModel(),
    optimizer=Adam(),
    loss_fn=MSELoss(),
    callbacks=[
        EarlyStopping(patience=5),
        ModelCheckpoint(filepath="best_model.pth"),
        TensorBoardLogger(),
        # Quer Slack? SÃ³ adicionar: SlackNotifier()
    ]
)
trainer.fit(train_loader, epochs=100)
```

**BenefÃ­cios:**
- âœ… Loop matemÃ¡tico limpo e puro
- âœ… ExtensÃ­vel via composiÃ§Ã£o (nÃ£o heranÃ§a)
- âœ… Cada callback testÃ¡vel isoladamente
- âœ… Segue Open/Closed Principle (SOLID)


---

## ğŸ’» Uso

### Exemplo BÃ¡sico
```python
from dl_trainer import Trainer
from dl_trainer.callbacks import EarlyStopping, ModelCheckpoint

# ConfiguraÃ§Ã£o via composiÃ§Ã£o
trainer = Trainer(
    model="SimulatedModel",
    optimizer="Adam",
    loss_fn="MSE",
    callbacks=[
        EarlyStopping(patience=3),
        ModelCheckpoint(filepath="model.pth")
    ]
)

# Dados simulados (para demo sem PyTorch)
fake_dataloader = [1, 2, 3]

# Rodar treino
trainer.fit(fake_dataloader, epochs=10)
```

**SaÃ­da esperada:**

```
ğŸš€ Training started with 2 callbacks
Epoch 0 | Loss: 0.30
ğŸ’¾ Checkpoint: Saving model to model.pth
Epoch 1 | Loss: 0.30
ğŸ›‘ Early stopping triggered at epoch 1 (patience: 3)
```

### Exemplo AvanÃ§ado (MÃºltiplos Callbacks)

Ver `examples/advanced_usage.py` para:
- Custom metrics logging
- Learning rate scheduling
- Gradient clipping
- Slack notifications

---

## ğŸ§ª Testes

Executar todos os testes:
```bash
pytest
```

Com coverage:
```bash
pytest --cov=src/dl_trainer --cov-report=html
```

Watch mode (rodar a cada mudanÃ§a):
```bash
pytest-watch
```

---

## ğŸ“š Arquitetura

### Diagrama de Classes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Trainer      â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ + fit()         â”‚â”€â”€â”€â”€â”€â”€â”€â”
â”‚ + _notify()     â”‚       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚ usa                    â”‚
â–¼                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚ <<Protocol>>    â”‚      â”‚
â”‚   Callback      â”‚      â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚      â”‚
â”‚ + on_train_beginâ”‚      â”‚
â”‚ + on_epoch_end  â”‚      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â–²                        â”‚
â”‚ implementa             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                â”‚                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚EarlyStopping  â”‚  â”‚ModelCheckpointâ”‚ â”‚CustomCallbackâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Design Patterns Aplicados

1. **Strategy Pattern**: Cada callback Ã© uma estratÃ©gia intercambiÃ¡vel
2. **Observer Pattern**: Trainer notifica eventos para callbacks
3. **Template Method**: `fit()` define estrutura, callbacks customizam comportamento
4. **Dependency Inversion**: Trainer depende da abstraÃ§Ã£o `Callback`, nÃ£o de implementaÃ§Ãµes concretas

Ver `docs/PATTERNS.md` para detalhes.

---

## ğŸ“ Conceitos Demonstrados

### 1. Open/Closed Principle (SOLID)
```python
# Aberto para extensÃ£o (adicionar SlackCallback)
# Fechado para modificaÃ§Ã£o (Trainer nÃ£o muda)
class SlackNotifier(Callback):
    def on_train_begin(self, logs):
        send_slack("Treino iniciado!")
    def on_epoch_end(self, epoch, logs):
        send_slack(f"Ã‰poca {epoch} concluÃ­da")
        return False

# Uso sem mudar Trainer
trainer = Trainer(
    callbacks=[SlackNotifier()]  # SÃ³ adicionar!
)
```

### 2. Single Responsibility Principle

Cada classe tem **uma** responsabilidade:
- `Trainer`: Executar loop de treino
- `EarlyStopping`: Decidir quando parar
- `ModelCheckpoint`: Salvar modelo

### 3. Testabilidade
```python
# Testar early stopping SEM treinar rede neural!
def test_early_stopping():
    callback = EarlyStopping(patience=2)
    # Simular Ã©pocas ruins
    callback.on_epoch_end(0, {"loss": 1.0})
    should_stop = callback.on_epoch_end(1, {"loss": 1.0})
    assert should_stop is True
```

---

## ğŸ”§ ExtensÃµes PossÃ­veis

Exemplos de callbacks que vocÃª pode adicionar:

- **LearningRateScheduler**: Ajustar LR dinamicamente
- **GradientClipper**: Limitar gradientes
- **MetricsLogger**: Log em W&B, MLflow, TensorBoard
- **ProgressBar**: UI com tqdm
- **EmailNotifier**: Avisar quando treino terminar
- **ProfilerCallback**: Detectar bottlenecks

Todos seguem a mesma interface `Callback`.

---

## ğŸ“– ReferÃªncias

Este padrÃ£o Ã© inspirado em:
- **Keras**: `model.fit(callbacks=[...])`
- **PyTorch Lightning**: `Trainer(callbacks=[...])`
- **FastAI**: `Learner.fit(..., cbs=[...])`

---

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie branch: `git checkout -b feature/novo-callback`
3. Commit: `git commit -m 'Add: GradientClipper callback'`
4. Push: `git push origin feature/novo-callback`
5. Abra Pull Request

---

## ğŸ“ LicenÃ§a

MIT License - veja [LICENSE](LICENSE) para detalhes.

---

## ğŸ‘¤ Autor

**[Seu Nome]**
- GitHub: [@gokuhayda](https://github.com/gokuhayda)
- LinkedIn: [meu-perfil](https://linkedin.com/in/eric-nextgen)

---

## ğŸ¯ ThoughtWorks Context

Este projeto foi criado como parte da preparaÃ§Ã£o para entrevistas tÃ©cnicas onde:
- âœ… Clean Code e SOLID sÃ£o esperados
- âœ… Cientistas de dados devem pensar como engenheiros
- âœ… CÃ³digo de ML deve ser testÃ¡vel e manutenÃ­vel

> "Move code out of notebooks into Python modules as early as possible. That way, they can rest within the safe confines of unit tests and domain boundaries." - ThoughtWorks Blog

---

**â­ Se este projeto te ajudou, considere dar uma estrela!**


## ğŸ“‚ Estrutura do Projeto

```
dl-refactor-kata/
â”œâ”€â”€ README.md                    # DocumentaÃ§Ã£o principal
â”œâ”€â”€ pyproject.toml              # Poetry/pip dependencies
â”œâ”€â”€ .gitignore                  # Arquivos a ignorar
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ tests.yml           # CI/CD com GitHub Actions
â”œâ”€â”€ src/
â”‚   â””â”€â”€ dl_trainer/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ trainer.py          # Classe Trainer
â”‚       â”œâ”€â”€ callbacks.py        # Callbacks concretos
â”‚       â””â”€â”€ protocols.py        # Interface/Protocol
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_trainer.py
â”‚   â””â”€â”€ test_callbacks.py
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ basic_usage.py          # Exemplo simples
â”‚   â””â”€â”€ advanced_usage.py       # Com mÃºltiplos callbacks
â””â”€â”€ docs/
    â”œâ”€â”€ ARCHITECTURE.md         # DecisÃµes de design
    â””â”€â”€ PATTERNS.md             # Design patterns aplicados
```
