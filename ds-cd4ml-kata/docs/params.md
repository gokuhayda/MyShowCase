bash# Certifique-se de estar na pasta do projeto
cd ~/Documentos/thoughtWorks/KATA/MyShowCase/ds-cd4ml-kata

# Criar arquivo de parÃ¢metros com comentÃ¡rios completos
cat > params.yaml << 'EOF'
# ============================================================================
# CONFIGURAÃ‡ÃƒO DE HIPERPARÃ‚METROS E QUALITY GATES
# ============================================================================
# Este arquivo centraliza TODOS os parÃ¢metros do pipeline de ML
# BenefÃ­cios:
#   - Rastreabilidade: MLflow loga esses valores
#   - Reprodutibilidade: Mesmos params = mesmo resultado
#   - ExperimentaÃ§Ã£o: FÃ¡cil testar diferentes configuraÃ§Ãµes
#   - Versionamento: Git versiona mudanÃ§as nos parÃ¢metros
# ============================================================================

# ----------------------------------------------------------------------------
# HIPERPARÃ‚METROS DO MODELO
# ----------------------------------------------------------------------------
model:
  algorithm: RandomForest                # Algoritmo escolhido
  
  # NÃºmero de Ã¡rvores no ensemble
  # - Mais Ã¡rvores = mais estÃ¡vel, mas mais lento
  # - TÃ­pico: 50-500
  n_estimators: 100
  
  # Profundidade mÃ¡xima de cada Ã¡rvore
  # - Controla overfitting (menor = menos overfitting)
  # - None = sem limite (mais overfitting)
  # - TÃ­pico: 5-20
  max_depth: 10
  
  # MÃ­nimo de amostras para dividir um nÃ³
  # - Maior valor = menos divisÃµes = menos overfitting
  # - TÃ­pico: 2-20
  min_samples_split: 5
  
  # MÃ­nimo de amostras em cada folha
  # - Maior valor = folhas mais robustas
  # - TÃ­pico: 1-10
  min_samples_leaf: 2
  
  # Seed para reprodutibilidade
  # - Garante que o treino Ã© determinÃ­stico
  # - Use o mesmo valor em todos os experimentos comparÃ¡veis
  random_state: 42
  
  # Balanceamento de classes
  # - balanced: Ajusta pesos automaticamente (recomendado para classes desbalanceadas)
  # - None: Sem balanceamento
  # - dict: {0: 1, 1: 2} para pesos customizados
  class_weight: balanced

# ----------------------------------------------------------------------------
# DIVISÃƒO DE DADOS (TRAIN/TEST SPLIT)
# ----------------------------------------------------------------------------
data:
  # ProporÃ§Ã£o de dados para teste
  # - 0.2 = 80% treino, 20% teste
  # - TÃ­pico: 0.2 - 0.3
  test_size: 0.2
  
  # Seed para reprodutibilidade do split
  # - Garante que sempre pega as mesmas amostras
  random_state: 42
  
  # Estratificar por target
  # - true: MantÃ©m proporÃ§Ã£o de classes em train e test
  # - false: Split aleatÃ³rio puro
  # - SEMPRE use true para classificaÃ§Ã£o!
  stratify: true

# ----------------------------------------------------------------------------
# QUALITY GATES - THRESHOLDS MÃNIMOS
# ----------------------------------------------------------------------------
# O modelo SÃ“ passa se atingir TODOS esses valores
# Ajuste baseado em:
#   - Requisitos de negÃ³cio
#   - Baseline (modelo simples)
#   - Benchmarks da literatura
metrics:
  # AcurÃ¡cia mÃ­nima no conjunto de teste
  # - (TP + TN) / Total
  # - 0.75 = 75% de prediÃ§Ãµes corretas
  min_accuracy: 0.75
  
  # PrecisÃ£o mÃ­nima
  # - TP / (TP + FP)
  # - "Das prediÃ§Ãµes positivas, quantas estavam certas?"
  # - Importante quando custo de FP Ã© alto
  min_precision: 0.73
  
  # Recall mÃ­nimo (sensibilidade)
  # - TP / (TP + FN)
  # - "Dos casos positivos reais, quantos detectamos?"
  # - Importante quando custo de FN Ã© alto
  min_recall: 0.73
  
  # F1-Score mÃ­nimo
  # - MÃ©dia harmÃ´nica de precision e recall
  # - Balanceia precision e recall
  min_f1: 0.73
  
  # Gap mÃ¡ximo entre treino e teste (overfitting check)
  # - train_acc - test_acc
  # - 0.10 = mÃ¡ximo 10% de diferenÃ§a
  # - Valores maiores indicam overfitting
  max_train_test_gap: 0.10

# ----------------------------------------------------------------------------
# CROSS-VALIDATION
# ----------------------------------------------------------------------------
# ValidaÃ§Ã£o cruzada para estimar performance de forma mais robusta
cv:
  # NÃºmero de folds (divisÃµes)
  # - 5 = divide em 5 partes, treina 5 vezes
  # - TÃ­pico: 3-10 (5 Ã© padrÃ£o)
  # - Mais folds = mais confiÃ¡vel, mas mais lento
  n_splits: 5
  
  # Embaralhar dados antes de dividir
  # - true: Aleatoriza ordem (recomendado)
  # - false: Usa ordem original
  shuffle: true
  
  # Seed para reprodutibilidade do CV
  random_state: 42

# ============================================================================
# DICAS DE AJUSTE (TUNING)
# ============================================================================
# 
# ðŸ”§ Se OVERFITTING (train_acc >> test_acc):
#    - Diminuir max_depth (ex: 10 â†’ 5)
#    - Aumentar min_samples_split (ex: 5 â†’ 10)
#    - Aumentar min_samples_leaf (ex: 2 â†’ 5)
#    - Diminuir n_estimators (ex: 100 â†’ 50)
#
# ðŸ”§ Se UNDERFITTING (train_acc e test_acc baixos):
#    - Aumentar max_depth (ex: 10 â†’ 15)
#    - Diminuir min_samples_split (ex: 5 â†’ 2)
#    - Aumentar n_estimators (ex: 100 â†’ 200)
#    - Adicionar features
#
# ðŸ”§ Se classes DESBALANCEADAS:
#    - Manter class_weight: balanced
#    - Ou testar: {0: 1, 1: 3} para dar 3x mais peso Ã  classe 1
#
# ðŸ”§ Para TUNING sistemÃ¡tico:
#    - Use GridSearchCV ou RandomizedSearchCV
#    - Exemplo: n_estimators: [50, 100, 200]
#              max_depth: [5, 10, 15, 20]
#
# ============================================================================