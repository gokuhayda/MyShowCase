"""
Tool CrewAI personalizada para verificar se uma pergunta √© semanticamente relevante dentro
de uma categoria espec√≠fica, usando um ComposableGraph com filtros e rerank opcional.
"""
import os
from typing import Any, Dict, Type
from pydantic import BaseModel, Field, PrivateAttr
from crewai.tools.base_tool import BaseTool
from utils_tools.config_loader import load_config
from llama_index.core.composability import ComposableGraph
from model_loader import initialize_embedding_model
from query_index import verificar_relevancia, verificar_confian√ßa, rerank_with_cohere, get_confidence

class SegmentedToolInputSchema(BaseModel):
    description: str = Field(..., description="Pergunta ou texto para valida√ß√£o sem√¢ntica.")
    categoria: str = Field(..., description="Categoria espec√≠fica dentro do ComposableGraph.")
    metadata: Dict[str, Any] = Field(default_factory=dict, description="Metadados opcionais adicionais.")

class SegmentedSemanticGuardTool(BaseTool):
    """
    Ferramenta CrewAI que valida perguntas com base em conte√∫do vetorizado segmentado por categoria.

    Utiliza ComposableGraph + rerank opcional com Cohere + filtros e confian√ßa m√≠nima.
    """
    name: str = "semantic_segmented_guard_tool"
    description: str = "Verifica se a pergunta est√° semanticamente relacionada ao conte√∫do vetorizado dentro de uma categoria espec√≠fica via ComposableGraph."
    args_schema: Type[BaseModel] = SegmentedToolInputSchema

    _config: dict = PrivateAttr()
    _threshold: float = PrivateAttr()
    _top_k: int = PrivateAttr()
    _fallback: str = PrivateAttr()
    _graph: ComposableGraph = PrivateAttr()
    _embed_model: Any = PrivateAttr()

    def __init__(self, composable_graph: ComposableGraph):
        super().__init__()
        self._config = load_config()
        self._threshold = self._config.get("confidence", {}).get("semantic_threshold", 0.75)
        self._top_k = self._config.get("top_k", 13)
        self._fallback = self._config.get(
            "fallback_message",
            "Essa pergunta est√° fora do escopo do FAQ. Por favor, pergunte algo relacionado."
        )
        self._graph = composable_graph
        self._embed_model = initialize_embedding_model(self._config)

    def _run(self, description: str, categoria: str, metadata: Dict[str, Any]) -> str:
        """
        Executa o processo de verifica√ß√£o sem√¢ntica para uma categoria espec√≠fica.

        Par√¢metros:
            description (str): Pergunta a ser validada.
            categoria (str): Categoria a ser consultada no grafo.
            metadata (dict): Dados adicionais opcionais.

        Retorna:
            str: Resposta validada ou mensagem de fallback.
        """
        try:
            print(f"üîç [SegmentedTool] Executando pipeline segmentada para a categoria: {categoria}")
            query_engine = self._graph.as_query_engine(
                similarity_top_k=self._top_k,
                embed_model=self._embed_model,
                filters={"categoria": categoria}
            )
            response = query_engine.query(description)
            print("üì• [SegmentedTool] Resposta bruta recebida.")

            resposta_bruta = response.response.strip()
            source_nodes = getattr(response, "source_nodes", [])
            if not resposta_bruta or not source_nodes:
                print("‚ùå [SegmentedTool] Nenhum conte√∫do retornado.")
                return self._fallback

            documentos_faq = [node.text for node in source_nodes]
            if not verificar_relevancia(description, documentos_faq, para_query=True):
                print("‚ùå [SegmentedTool] Pergunta sem relev√¢ncia sem√¢ntica.")
                return self._fallback

            confianca_inicial = get_confidence(source_nodes)
            print(f"üî¢ [SegmentedTool] Confian√ßa inicial: {confianca_inicial} (limiar: {self._threshold})")

            if self._config.get("usar_rerank", False):
                print("üîÅ [SegmentedTool] Aplicando rerank com Cohere...")
                source_nodes = rerank_with_cohere(source_nodes, description)

            confianca_final = get_confidence(source_nodes)
            is_semantic_valid = verificar_relevancia(resposta_bruta, documentos_faq)

            if not is_semantic_valid or confianca_final < self._threshold:
                print("‚ö†Ô∏è [SegmentedTool] Resposta fora dos crit√©rios.")
                return self._fallback

            print("‚úÖ [SegmentedTool] Resposta validada com sucesso.")
            return f"A pergunta √© relevante na categoria '{categoria}'. Resposta:\n\n{resposta_bruta}"

        except Exception as e:
            print(f"üí• [SegmentedTool] Erro na execu√ß√£o: {e}")
            return f"Erro ao verificar similaridade segmentada: {str(e)}"
