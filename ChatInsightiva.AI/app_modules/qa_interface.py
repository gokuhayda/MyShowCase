"""
Interface unificada Streamlit para avaliar respostas com RAGAS,
com barra de progresso, reescrita, resposta do bot e resumo final.
"""

import streamlit as st
from ragas import evaluate
from ragas.metrics import (
    faithfulness,
    answer_relevancy,
    context_precision,
    context_recall
)

from app_modules.qa_extractor import extrair_dados_do_json
from app_modules.qa_rewriter import reescrever_perguntas
from utils_tools.qa_utils import mostrar_resultados_ragas

def executar_interface_streamlit():
    st.set_page_config(page_title="RAGAS QA AvaliaÃ§Ã£o", layout="wide")
    st.title("ğŸ“Š AvaliaÃ§Ã£o de Perguntas e Respostas com RAGAS")

    with st.expander("ğŸ“– O que sÃ£o essas mÃ©tricas e como configurar os parÃ¢metros?"):
        st.markdown("""
        ### ğŸ“Š Entendendo as MÃ©tricas de Qualidade (RAGAS)

        As mÃ©tricas abaixo avaliam a **qualidade das respostas do chatbot** com base em critÃ©rios tÃ©cnicos e de linguagem natural:

        - **ğŸ§  Faithfulness (Fidelidade)**: Avalia se a resposta estÃ¡ fiel ao conteÃºdo apresentado nos contextos. Respostas inventadas ou distorcidas reduzem essa mÃ©trica.
        
        - **ğŸ¯ Answer Relevancy (RelevÃ¢ncia da Resposta)**: Mede o quanto a resposta realmente responde Ã  pergunta feita. Uma resposta genÃ©rica ou fora do tema reduz essa nota.
        
        - **ğŸ“Œ Context Precision (PrecisÃ£o do Contexto)**: Verifica se os trechos usados para gerar a resposta sÃ£o realmente Ãºteis ou se hÃ¡ excesso de informaÃ§Ã£o desnecessÃ¡ria.
        
        - **ğŸ” Context Recall (AbrangÃªncia do Contexto)**: Mede se os contextos utilizados cobrem tudo o que a resposta precisa. Se algo importante ficou de fora, essa mÃ©trica cai.

        ---

        ### âš™ï¸ Como configurar os parÃ¢metros do modelo LLM

        Estes parÃ¢metros ajudam a controlar o estilo e a forma como as perguntas serÃ£o reescritas:

        - **ğŸ”¥ Temperatura**: Controla a criatividade do modelo. Valores mais baixos geram respostas mais seguras e previsÃ­veis. Valores mais altos (ex: 0.9) tornam as respostas mais criativas e variadas.
        
        - **ğŸŒ Top-p**: Determina o quanto o modelo deve considerar alternativas alÃ©m das mais provÃ¡veis. Use 1.0 para permitir maior variedade e inclusÃ£o de ideias.
        
        - **ğŸ” Presence Penalty**: Penaliza o modelo se ele repetir temas jÃ¡ abordados. Aumente se quiser menos repetiÃ§Ã£o de ideias.
        
        - **ğŸ” Frequency Penalty**: Penaliza palavras que se repetem com frequÃªncia. Ãštil para evitar redundÃ¢ncia.
        
        - **ğŸ­ Estilo da Reescrita**: Escolha se deseja perguntas mais formais, resumidas ou diretas. Isso afeta como o modelo reformula a pergunta original para fazer mais sentido ao chatbot.

        ---
        ğŸ§ª Dica: experimente diferentes combinaÃ§Ãµes para ver como isso afeta os resultados. Cada modelo tem um "comportamento criativo" diferente!
        """)


    st.sidebar.header("âš™ï¸ ParÃ¢metros do Modelo")

    provedor = st.sidebar.radio("ğŸ§  Provedor", ["OpenAI", "Ollama"], horizontal=True)
    modelo = st.sidebar.selectbox("Modelo", ["gpt-4", "gpt-3.5-turbo"] if provedor == "OpenAI" else ["llama3", "mistral", "codellama"])

    temperatura = st.sidebar.slider("Temperatura", 0.0, 1.0, 0.7)
    top_p = st.sidebar.slider("Top-p", 0.0, 1.0, 1.0)
    presence_penalty = st.sidebar.slider("Presence Penalty", 0.0, 2.0, 0.0)
    frequency_penalty = st.sidebar.slider("Frequency Penalty", 0.0, 2.0, 0.0)

    estilos = st.sidebar.multiselect("ğŸ­ Estilo da reescrita", ["informal","formal", "resumido", "instrucional", "assertivo"])

    modo_qas = st.sidebar.radio("Modo de SeleÃ§Ã£o", ["Amostra AleatÃ³ria", "Sequencial", "Usar todo o dataset"])
    n_qas = None
    if modo_qas != "Usar todo o dataset":
        n_qas = st.sidebar.slider("NÂº mÃ¡ximo de pares QA", 5, 100, 30)

    perguntas_pers = ""
    usar_personalizadas = st.sidebar.checkbox("âœï¸ Inserir perguntas personalizadas")
    if usar_personalizadas:
        perguntas_pers = st.sidebar.text_area("Cole as perguntas (uma por linha):")

    reescrever = st.checkbox("ğŸ” Reescrever perguntas com LLM")

    if st.button("â–¶ï¸ Executar avaliaÃ§Ã£o"):
        with st.spinner("ğŸ”„ Extraindo dados..."):
            dataset = extrair_dados_do_json()

        if reescrever:
            
                    bloco_texto = st.empty()
        dataset = reescrever_perguntas(
            dataset,
            modelo=modelo,
            provedor=provedor,
            temperatura=temperatura,
            top_p=top_p,
            presence_penalty=presence_penalty,
            frequency_penalty=frequency_penalty,
            estilos=estilos,
            perguntas_personalizadas=perguntas_pers.splitlines() if perguntas_pers else None,
            max_qas=n_qas if n_qas else 9999,
            modo_qas=modo_qas,
            bloco_texto=bloco_texto
        )

        with st.spinner("âš™ï¸ Calculando mÃ©tricas com RAGAS..."):
            resultados = evaluate(dataset, metrics=[
                faithfulness,
                answer_relevancy,
                context_precision,
                context_recall
            ])
            mostrar_resultados_ragas(resultados)

            if resultados:
                df_ragas = resultados.to_pandas()
                st.download_button(
                    label="ğŸ“¥ Baixar resultados RAGAS (.csv)",
                    data=df_ragas.to_csv(index=False).encode('utf-8'),
                    file_name="avaliacao_ragas.csv",
                    mime="text/csv"
                )

# fim do mÃ³dulo
