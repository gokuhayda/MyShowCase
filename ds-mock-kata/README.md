
# ğŸ¥‹ Data Science Mock Katas

> **Pratique testes unitÃ¡rios com mocking em Python atravÃ©s de exercÃ­cios progressivos focados em Data Science**

## ğŸ“‹ Ãndice

- [Sobre o Projeto](#sobre-o-projeto)
- [Por que Mocking?](#por-que-mocking)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Como Usar](#como-usar)
- [Os Katas](#os-katas)
  - [Kata 01: Boundary S3](#kata-01-boundary-s3)
  - [Kata 02: ML Pipeline](#kata-02-ml-pipeline)
  - [Kata 03: Legacy Rescue](#kata-03-legacy-rescue)
- [Conceitos Fundamentais](#conceitos-fundamentais)
- [Recursos Adicionais](#recursos-adicionais)
- [Contribuindo](#contribuindo)

---

## ğŸ¯ Sobre o Projeto

Este repositÃ³rio contÃ©m uma sÃ©rie de **katas** (exercÃ­cios de cÃ³digo) focados em ensinar tÃ©cnicas de **mocking** e **testes unitÃ¡rios** para cientistas de dados. Cada kata aborda um cenÃ¡rio comum em projetos de Data Science onde o mocking Ã© essencial para criar testes rÃ¡pidos, confiÃ¡veis e isolados.

### Objetivos de Aprendizado

- âœ… Entender **quando** e **por que** usar mocks
- âœ… Dominar `unittest.mock` e `@patch`
- âœ… Isolar dependÃªncias externas (I/O, APIs, modelos ML)
- âœ… Aplicar princÃ­pios de **Clean Architecture** em projetos de DS
- âœ… Refatorar cÃ³digo legado para tornÃ¡-lo testÃ¡vel

---

## ğŸ¤” Por que Mocking?

Em Data Science, frequentemente trabalhamos com:

- ğŸŒ **APIs externas** (lento, pode falhar)
- ğŸ—„ï¸ **Bancos de dados** (requer infraestrutura)
- â˜ï¸ **Cloud Storage** (S3, GCS - custo e latÃªncia)
- ğŸ¤– **Modelos ML pesados** (5GB+, treino demorado)

**Sem mocking:**
```python
def test_pipeline():
    df = pd.read_csv("s3://bucket/data.csv")  # âŒ Chamada real ao S3
    model.fit(X_train, y_train)                # âŒ Treino real (minutos)
    # Teste lento, instÃ¡vel, caro
```

**Com mocking:**
```python
@patch('module.pd.read_csv')
def test_pipeline(mock_read_csv):
    mock_read_csv.return_value = fake_df     # âœ… InstantÃ¢neo
    # Teste rÃ¡pido, confiÃ¡vel, sem custo
```

### BenefÃ­cios do Mocking

| BenefÃ­cio | Sem Mock | Com Mock |
|-----------|----------|----------|
| **Velocidade** | Segundos/Minutos | Milissegundos |
| **Confiabilidade** | Depende de rede/infra | 100% determinÃ­stico |
| **Custo** | Pode gerar custos (API, cloud) | Zero custo |
| **Isolamento** | Testa mÃºltiplas camadas | Testa apenas lÃ³gica |

---

## ğŸ“ Estrutura do Projeto

```
ds-mock-kata/
â”‚
â”œâ”€â”€ README.md                          # Este arquivo
â”œâ”€â”€ requirements.txt                   # DependÃªncias do projeto
â”œâ”€â”€ main.py                           # Runner interativo para os katas
â”‚
â”œâ”€â”€ docs/                             # DocumentaÃ§Ã£o adicional
â”‚   â”œâ”€â”€ mindset.md                    # Filosofia de testes e mocking
â”‚   â””â”€â”€ mock_cheat_sheet.md           # Guia rÃ¡pido de referÃªncia
â”‚
â”œâ”€â”€ katas/                            # ExercÃ­cios prÃ¡ticos
â”‚   â”œâ”€â”€ b01_boundary_s3/              # Kata 01: Mockar I/O com S3
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ data_loader.py
â”‚   â”‚
â”‚   â”œâ”€â”€ b02_ml_pipeline/              # Kata 02: Mockar modelos ML
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ model_trainer.py
â”‚   â”‚
â”‚   â””â”€â”€ b03_legacy_rescue/            # Kata 03: RefatoraÃ§Ã£o com DI
â”‚       â”œâ”€â”€ ADDITIONAL.md
â”‚       â”œâ”€â”€ original.py               # CÃ³digo legado (antes)
â”‚       â””â”€â”€ refactored/               # CÃ³digo refatorado (depois)
â”‚           â”œâ”€â”€ api_client.py
â”‚           â”œâ”€â”€ scoring_logic.py
â”‚           â””â”€â”€ orchestrator.py
â”‚
â””â”€â”€ tests/                            # Testes unitÃ¡rios
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_01_boundary_s3.py
    â”œâ”€â”€ test_02_ml_pipeline.py
    â””â”€â”€ test_03_legacy_rescue.py
```

---

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.10+
- pip

### Passos

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/seu-usuario/ds-mock-kata.git
cd ds-mock-kata

# 2. (Opcional) Crie um ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# 3. Instale as dependÃªncias
pip install -r requirements.txt
```

---

## ğŸ’» Como Usar

### Modo Interativo (Recomendado)

Execute o runner interativo que permite escolher qual kata rodar:

```bash
python main.py
```

VocÃª verÃ¡ um menu:

```
Escolha o kata para rodar:
1 = Boundary S3
2 = ML Pipeline
3 = Legacy Rescue
4 = Todos
Digite a opÃ§Ã£o: _
```

### Modo Direto com pytest

Execute todos os testes:

```bash
pytest tests/ -v
```

Execute um kata especÃ­fico:

```bash
# Kata 01
pytest tests/test_01_boundary_s3.py -v

# Kata 02
pytest tests/test_02_ml_pipeline.py -v

# Kata 03
pytest tests/test_03_legacy_rescue.py -v
```

### Modo Direto com unittest

```bash
# Rodar todos os testes
python -m unittest discover tests

# Rodar kata especÃ­fico
python -m unittest tests.test_01_boundary_s3
```

---

## ğŸ¥‹ Os Katas

### Kata 01: Boundary S3

**ğŸ“š Conceito:** Isolar I/O externo (Cloud Storage)

#### O Desafio

VocÃª tem uma classe que carrega dados do S3:

```python
class S3DataLoader:
    def load_csv(self, s3_path: str) -> pd.DataFrame:
        return pd.read_csv(s3_path)  # â† Chamada real ao S3!
```

#### O Problema

- âŒ Requer credenciais AWS
- âŒ Requer conexÃ£o de rede
- âŒ Lento (latÃªncia + download)
- âŒ Pode custar dinheiro

#### A SoluÃ§Ã£o: Mock

```python
@patch("katas.b01_boundary_s3.data_loader.pd.read_csv")
def test_load_csv(self, mock_read_csv):
    # Arrange: Preparar dados falsos
    fake_df = pd.DataFrame({'id': [1, 2, 3]})
    mock_read_csv.return_value = fake_df
    
    # Act: Executar mÃ©todo
    loader = S3DataLoader()
    result = loader.load_csv("s3://bucket/data.csv")
    
    # Assert: Verificar resultado e comportamento
    pd.testing.assert_frame_equal(result, fake_df)
    mock_read_csv.assert_called_once_with("s3://bucket/data.csv")
```

#### ğŸ¯ LiÃ§Ãµes Aprendidas

1. **Regra de Ouro:** Mock onde a funÃ§Ã£o Ã© **USADA**, nÃ£o onde Ã© **DEFINIDA**
   - âŒ Errado: `@patch('pandas.read_csv')`
   - âœ… Certo: `@patch('katas.b01_boundary_s3.data_loader.pd.read_csv')`

2. **VerificaÃ§Ã£o Dupla:**
   - **Estado:** O resultado estÃ¡ correto?
   - **Comportamento:** O mÃ©todo foi chamado corretamente?

---

### Kata 02: ML Pipeline

**ğŸ“š Conceito:** Isolar modelos ML pesados

#### O Desafio

VocÃª tem uma classe que treina modelos:

```python
class ModelTrainer:
    def train_and_evaluate(self, X_train, y_train, X_test, y_test):
        model = RandomForestClassifier(n_estimators=100)
        model.fit(X_train, y_train)  # â† Treino real (lento!)
        predictions = model.predict(X_test)
        return accuracy_score(y_test, predictions)
```

#### O Problema

- âŒ Treinar modelo Ã© lento (segundos a horas)
- âŒ Requer dados reais ou sintÃ©ticos grandes
- âŒ Comportamento nÃ£o-determinÃ­stico (random_state pode variar)
- âŒ Testes ficam lentos e flaky

#### A SoluÃ§Ã£o: Mock

```python
@patch('katas.b02_ml_pipeline.model_trainer.RandomForestClassifier')
def test_train_and_evaluate_flow(self, mock_rf_class):
    # Arrange: Configurar mock da classe e instÃ¢ncia
    mock_instance = mock_rf_class.return_value
    mock_instance.predict.return_value = np.array([1, 0])
    
    # Act
    trainer = ModelTrainer()
    accuracy = trainer.train_and_evaluate(X_train, y_train, X_test, y_test)
    
    # Assert
    mock_instance.fit.assert_called_once_with(X_train, y_train)
    mock_instance.predict.assert_called_once_with(X_test)
    self.assertEqual(accuracy, 1.0)
```

#### ğŸ¯ LiÃ§Ãµes Aprendidas

1. **Mock de Classe vs InstÃ¢ncia:**
   - Mockamos a **classe** com `@patch`
   - Configuramos a **instÃ¢ncia** com `.return_value`

2. **VerificaÃ§Ã£o de Fluxo:**
   - Testamos se `fit()` foi chamado
   - Testamos se `predict()` foi chamado
   - Testamos se a lÃ³gica de acurÃ¡cia funciona

---

### Kata 03: Legacy Rescue

**ğŸ“š Conceito:** Refatorar cÃ³digo legado para tornÃ¡-lo testÃ¡vel

#### O Desafio

VocÃª herda este cÃ³digo:

```python
# CÃ“DIGO LEGADO (original.py)
MODEL = load_model()  # âŒ Global!

def generate_customer_score(customer_id: int) -> float:
    # âŒ I/O misturado com lÃ³gica
    response = requests.get(f"https://api.fake.com/customers/{customer_id}")
    data = response.json()
    
    # âŒ LÃ³gica enterrada no meio
    base_score = (data["age"] * 0.1) + (data["income"] / 1000)
    
    # âŒ DependÃªncia global
    ml_prob = MODEL.predict_proba([[...]])[0][1]
    
    return base_score * ml_prob
```

#### Os Problemas

1. **Acoplamento a I/O:** Chamada HTTP direta
2. **DependÃªncia Global:** Modelo nÃ£o pode ser mockado
3. **LÃ³gica Misturada:** Regras de negÃ³cio enterradas
4. **ViolaÃ§Ã£o SRP:** Faz mÃºltiplas coisas
5. **NÃ£o testÃ¡vel:** ImpossÃ­vel testar sem rede/modelo real

#### A SoluÃ§Ã£o: RefatoraÃ§Ã£o com DI

**Passo 1: Separar em camadas**

```python
# api_client.py - BOUNDARY (I/O)
class CustomerApiClient:
    def get_customer_data(self, customer_id: int) -> dict:
        response = requests.get(f"https://api.fake.com/customers/{customer_id}")
        return response.json()

# scoring_logic.py - CORE (LÃ³gica Pura)
class ScoringLogic:
    @staticmethod
    def calculate_base_score(age: int, income: float, history: int) -> float:
        return (age * 0.1) + (income / 1000) + (history * 5)
    
    @staticmethod
    def calculate_final_score(base_score: float, ml_probability: float) -> float:
        return base_score * ml_probability

# orchestrator.py - ORCHESTRATION (CoordenaÃ§Ã£o)
class CustomerScoreOrchestrator:
    def __init__(self, api_client, ml_model):  # â† DEPENDENCY INJECTION
        self.api_client = api_client
        self.ml_model = ml_model
        self.logic = ScoringLogic()
    
    def generate_score(self, customer_id: int) -> float:
        data = self.api_client.get_customer_data(customer_id)
        base = self.logic.calculate_base_score(data['age'], data['income'], data['history'])
        prob = self.ml_model.predict_proba([[...]])[0][1]
        return self.logic.calculate_final_score(base, prob)
```

**Passo 2: Testar cada camada isoladamente**

```python
# Teste 1: LÃ³gica Pura (SEM mocks!)
def test_scoring_logic_math(self):
    base = ScoringLogic.calculate_base_score(30, 1000, 2)
    self.assertEqual(base, 14.0)  # (30*0.1) + (1000/1000) + (2*5)

# Teste 2: OrquestraÃ§Ã£o (COM mocks)
def test_orchestrator_flow(self):
    mock_api = Mock()
    mock_model = Mock()
    mock_api.get_customer_data.return_value = {"age": 30, "income": 1000, "history": 2}
    mock_model.predict_proba.return_value = [[0.99, 0.5]]
    
    orchestrator = CustomerScoreOrchestrator(mock_api, mock_model)
    score = orchestrator.generate_score(999)
    
    mock_api.get_customer_data.assert_called_once_with(999)
    self.assertEqual(score, 7.0)
```

#### ğŸ¯ LiÃ§Ãµes Aprendidas

1. **Separation of Concerns:**
   - **Boundary:** I/O e dependÃªncias externas
   - **Core:** LÃ³gica pura (sem I/O)
   - **Orchestration:** CoordenaÃ§Ã£o com DI

2. **Dependency Injection:**
   - DependÃªncias sÃ£o **injetadas** (nÃ£o criadas internamente)
   - Facilita testes com mocks

3. **Testabilidade:**
   - LÃ³gica pura: testa sem mocks (rÃ¡pido!)
   - OrquestraÃ§Ã£o: testa com mocks (isolado!)

---

## ğŸ§  Conceitos Fundamentais

### 1. O que Ã© um Mock?

Um **mock** Ã© um objeto falso que simula o comportamento de um objeto real. Usado para:

- Isolar cÃ³digo em teste
- Evitar dependÃªncias lentas/custosas
- Controlar comportamento de forma determinÃ­stica

### 2. Quando Usar Mocks?

âœ… **Use mocks quando:**
- OperaÃ§Ãµes de I/O (rede, disco, banco)
- APIs externas
- Modelos ML pesados
- OperaÃ§Ãµes lentas ou custosas
- Comportamento nÃ£o-determinÃ­stico

âŒ **NÃ£o use mocks quando:**
- LÃ³gica pura (matemÃ¡tica, transformaÃ§Ãµes simples)
- FunÃ§Ãµes rÃ¡pidas e sem efeitos colaterais
- Quando o mock seria mais complexo que o cÃ³digo real

### 3. Anatomia de um Mock

```python
from unittest.mock import Mock, patch

# 1. Criar mock manual
mock_api = Mock()
mock_api.get_data.return_value = {"result": "ok"}

# 2. Usar @patch (recomendado)
@patch('module.path.function')
def test_something(self, mock_function):
    mock_function.return_value = "fake_value"
    # seu teste aqui
```

### 4. PadrÃ£o AAA (Arrange-Act-Assert)

```python
def test_example(self):
    # ARRANGE: Preparar
    mock = Mock()
    mock.method.return_value = 42
    
    # ACT: Executar
    result = some_function(mock)
    
    # ASSERT: Verificar
    self.assertEqual(result, 42)
    mock.method.assert_called_once()
```

### 5. Regra de Ouro do @patch

**Mock onde a funÃ§Ã£o Ã© USADA, nÃ£o onde Ã© DEFINIDA!**

```python
# modulo_a.py
def funcao_original():
    return "real"

# modulo_b.py
from modulo_a import funcao_original

def usa_funcao():
    return funcao_original()

# test.py
# âŒ ERRADO
@patch('modulo_a.funcao_original')

# âœ… CERTO
@patch('modulo_b.funcao_original')
```

### 6. PrincÃ­pios de Clean Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CORE (LÃ³gica Pura)    â”‚  â† Sem I/O, sem dependÃªncias
â”‚   â€¢ Regras de negÃ³cio   â”‚
â”‚   â€¢ TestÃ¡vel sem mocks  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚ usa
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BOUNDARY (I/O)         â”‚  â† APIs, DB, S3, ML
â”‚  â€¢ Isolado              â”‚
â”‚  â€¢ MockÃ¡vel             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**BenefÃ­cios:**
- Core Ã© rÃ¡pido de testar (sem mocks)
- Boundaries sÃ£o isolados (com mocks)
- MudanÃ§as em I/O nÃ£o afetam lÃ³gica

---

## ğŸ“š Recursos Adicionais

### DocumentaÃ§Ã£o Oficial

- [unittest.mock - Python Docs](https://docs.python.org/3/library/unittest.mock.html)
- [pytest-mock](https://pytest-mock.readthedocs.io/)

### Artigos Recomendados

- [Stop Mocking, Start Testing](https://nedbatchelder.com/blog/201206/tldw_stop_mocking_start_testing.html)
- [Mocks Aren't Stubs](https://martinfowler.com/articles/mocksArentStubs.html)

### Livros

- **"Clean Architecture"** - Robert C. Martin
- **"Working Effectively with Legacy Code"** - Michael Feathers
- **"Test Driven Development"** - Kent Beck

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Se vocÃª tem ideias para novos katas ou melhorias:

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/novo-kata`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona novo kata'`)
4. Push para a branch (`git push origin feature/novo-kata`)
5. Abra um Pull Request

### Ideias para Novos Katas

- Kata 04: Mockar conexÃµes com banco de dados
- Kata 05: Mockar requisiÃ§Ãµes HTTP com `requests`
- Kata 06: Mockar operaÃ§Ãµes de arquivo (CSV, JSON)
- Kata 07: Mockar bibliotecas de deep learning (TensorFlow, PyTorch)

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

---

## ğŸ™ Agradecimentos

Este projeto foi criado para ajudar cientistas de dados a dominar testes unitÃ¡rios e mocking, habilidades essenciais para escrever cÃ³digo de produÃ§Ã£o robusto e manutenÃ­vel.

**Happy Mocking! ğŸ­**

---

## ğŸ“Š Status do Projeto

![Tests](https://img.shields.io/badge/tests-passing-brightgreen)
![Python](https://img.shields.io/badge/python-3.10+-blue)
![License](https://img.shields.io/badge/license-MIT-green)

---

## ğŸ’¬ Contato

DÃºvidas? SugestÃµes? Abra uma [issue](https://github.com/seu-usuario/ds-mock-kata/issues) ou entre em contato!
